{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search dataset using tag information\r\n",
        "\r\n",
        "In this tutorial, you will learn how to search dataset using tag information using python dataframe. This example uses NYC Taxi Data. To prepare the dataset to be used in this notebook, please complete the [prep_dataset.ipynb](./prep_dataset.ipynb) first.\r\n",
        "\r\n",
        "This tutorial includes the following tasks:\r\n",
        "* Configure Azure ML workspace\r\n",
        "* Load dataset and store dataset using 'easydict'\r\n",
        "* Create tag filter method\r\n",
        "* Search tag using predefined method "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequiste\r\n",
        "\r\n",
        "* Please complete the [prep_dataset.ipynb](./prep_dataset.ipynb) first"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure Azure ML workspace\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load required python packages\n",
        "from azureml.core import Workspace, Run, Model, Dataset\n",
        "from azureml.data import OutputFileDatasetConfig\n",
        "from datetime import datetime\n",
        "from easydict import EasyDict as edict\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from azureml.core import Experiment\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614845448558
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup workspace info\n",
        "subscription_id = '<your_subscription_id>'\n",
        "resource_group = '<your_resource_group>'\n",
        "workspace_name = '<your_workspace_name>'\n",
        "\n",
        "ws = Workspace(subscription_id, resource_group, workspace_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614845779945
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all dataset for current workspace\n",
        "ws.datasets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614923514933
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset and store dataset using 'easydict'"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store dataset list to edict\n",
        "ed_datasets = edict(ws.datasets)\n",
        "\n",
        "# Show dataset list\n",
        "datasets_list = list(ed_datasets.keys())\n",
        "datasets_list"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614926675986
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process tags using Pandas dataframe \n",
        "# Load all data info to Pandas Dataframe\n",
        "ds_list = []\n",
        "ds_dict = {}\n",
        "for _, _dataset in enumerate(datasets_list):\n",
        "    ds = Dataset.get_by_name(ws, _dataset)\n",
        "    for j in range(1, ds.version+1): # This code is for getting all dataset version data\n",
        "        j = str(j)\n",
        "        vds = Dataset.get_by_name(ws, _dataset, version=j)\n",
        "        ds_dict = vds.tags\n",
        "        ds_dict[\"dataset_id\"] = vds.id\n",
        "        ds_dict[\"dataset_name\"] = vds.name\n",
        "        ds_dict[\"dataset_version\"] = vds.version\n",
        "        ds_list.append(ds_dict)\n",
        "df_dataset = pd.DataFrame.from_dict(ds_list) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614926694662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614926696993
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create tag filter method\r\n",
        "\r\n",
        "You can use this method to search for a dataset with a specific tag value. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tag filter statement \n",
        "def filter_dataset_using_tags(**taglist):\n",
        "    # Step1. create filter condition list\n",
        "    filter_condition_list = []\n",
        "    for k, v in taglist.items():\n",
        "        condition = f'({k}==\\'{v}\\')'\n",
        "        filter_condition_list.append(condition)\n",
        "    # Step2. join condition list\n",
        "    condition = '&'.join(filter_condition_list)\n",
        "    # Step3. show query result\n",
        "    display(df_dataset.query(condition))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614926714432
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search tag using predefined method"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Search tags depends on various condition.\n",
        "# Case1 - check the dataset which is version - original\n",
        "taglist = {'version':'original'}\n",
        "filter_dataset_using_tags(**taglist)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614926760425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case2 - check the dataset which is version - original and type - yellow\n",
        "taglist = {'version':'original', 'type':'yellow'}\n",
        "filter_dataset_using_tags(**taglist)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614926851142
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}