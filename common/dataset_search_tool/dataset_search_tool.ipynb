{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required python packages\n",
    "from azureml.core import Workspace, Run, Model, Dataset\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from datetime import datetime\n",
    "from easydict import EasyDict as edict\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from azureml.core import Experiment\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current conda env if it is \"automl-eunk\"\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup workspace info\n",
    "subscription_id = '<my-subscription-id>'\n",
    "resource_group = '<my-resource-group>'\n",
    "workspace_name = '<my-workspace-name>'\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all dataset for current workspace\n",
    "ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store dataset list to edict\n",
    "ed_datasets = edict(ws.datasets)\n",
    "\n",
    "# Show dataset list\n",
    "datasets_list = list(ed_datasets.keys())\n",
    "datasets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tags using Pandas dataframe \n",
    "# Load all data info to Pandas Dataframe\n",
    "ds_list = []\n",
    "ds_dict = {}\n",
    "for _, _dataset in enumerate(datasets_list):\n",
    "    ds = Dataset.get_by_name(workspace, _dataset)\n",
    "    for j in range(1, ds.version+1): # This code is for getting all dataset version data\n",
    "        j = str(j)\n",
    "        vds = Dataset.get_by_name(workspace, _dataset, version=j)\n",
    "        ds_dict = vds.tags\n",
    "        ds_dict[\"dataset_id\"] = vds.id\n",
    "        ds_dict[\"dataset_name\"] = vds.name\n",
    "        ds_dict[\"dataset_version\"] = vds.version\n",
    "        ds_list.append(ds_dict)\n",
    "df_dataset = pd.DataFrame.from_dict(ds_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tag filter statement \n",
    "def filter_dataset_using_tags(**taglist):\n",
    "    # Step1. create filter condition list\n",
    "    filter_condition_list = []\n",
    "    for k, v in taglist.items():\n",
    "        condition = f'({k}==\\'{v}\\')'\n",
    "        filter_condition_list.append(condition)\n",
    "    # Step2. join condition list\n",
    "    condition = '&'.join(filter_condition_list)\n",
    "    # Step3. show query result\n",
    "    display(df_dataset.query(condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search tags depends on various condition.\n",
    "# Case1 - check the dataset which is labeler_ver (0.1)\n",
    "taglist = {'labeler_ver':'0.1'}\n",
    "filter_dataset_using_tags(**taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case2 - check the dataset which is labeler_ver (0.1) and augmentor_ver(0.1)\n",
    "taglist = {'labeler_ver':'0.1', 'augmentor_ver':'0.1'}\n",
    "filter_dataset_using_tags(**taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case3 - check the dataset with dataset_name\n",
    "taglist = {'dataset_name':'word_nn_train_positive_sample_pcm'}\n",
    "filter_dataset_using_tags(**taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case4 - check the dataset with a channel value of 2 or more. \n",
    "condition = 'channels >= \\'2\\''\n",
    "df_dataset.query(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case5 - check the number of files in the datasets that have the tag of pitch_ratio \n",
    "df_dataset[df_dataset.pitch_ratio.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case6 - check the list of files in the dataset with the tags pitch_ratio and volume_ratio. \n",
    "df_dataset[df_dataset.pitch_ratio.notnull() & df_dataset.volume_ratio.notnull()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:automl-eunk]",
   "language": "python",
   "name": "conda-env-automl-eunk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}